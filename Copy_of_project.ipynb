{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "564a62ea",
      "metadata": {
        "id": "564a62ea"
      },
      "source": [
        "# Land Cover and Land Use Classification using Satellite Imagery\n",
        "\n",
        "**Project Overview:** We will engage in a classification task to differentiate various land covers (e.g., water, forest, urban areas) using satellite imagery. This project explores the application of deep learning techniques for analyzing remote sensing data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ef2e201",
      "metadata": {
        "id": "2ef2e201"
      },
      "source": [
        "## 1. Problem Description\n",
        "\n",
        "Land cover classification involves identifying and categorizing the physical material on the surface of the Earth. This includes differentiating between various types such as forests, water bodies, agricultural land, urban areas, etc.. Land use, on the other hand, describes how humans utilize the land. Accurately classifying land cover and land use is crucial for numerous applications:\n",
        "\n",
        "* **Environmental Monitoring:** Tracking deforestation, urbanization, and changes in glaciers or water bodies.\n",
        "* **Urban Planning:** Managing urban growth and infrastructure development.\n",
        "* **Agriculture:** Monitoring crop health, and yield estimation.\n",
        "* **Disaster Management:** Assessing damage after natural disasters like floods or wildfires.\n",
        "* **Climate Change Studies:** Understanding the impact of climate change on different ecosystems.\n",
        "\n",
        "Satellite imagery provides a rich source of data for these tasks due to its wide coverage and regular revisit times. However, analyzing this data presents challenges:\n",
        "\n",
        "* **Cloud Cover:** Clouds can obscure the land surface.\n",
        "* **Atmospheric Effects:** Atmospheric conditions can distort the spectral information recorded by satellites.\n",
        "* **Spectral Similarity:** Different land cover types might have similar spectral signatures, making them hard to distinguish.\n",
        "* **Mixed Pixels:** A single pixel in a satellite image might represent multiple land cover types, especially in lower-resolution imagery.\n",
        "\n",
        "Deep learning techniques, particularly Convolutional Neural Networks (CNNs), have shown great promise in overcoming these challenges and achieving high accuracy in land cover classification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49b5a0e8",
      "metadata": {
        "id": "49b5a0e8"
      },
      "source": [
        "## 2. Data Source and Access\n",
        "\n",
        "This project can utilize datasets from various satellite missions:\n",
        "\n",
        "* **Sentinel-2:** Provides high-resolution optical imagery across 13 spectral bands, suitable for detailed land cover mapping. The EuroSAT dataset, used in the example code, is derived from Sentinel-2 imagery and contains 27,000 labeled image patches across 10 land cover classes.\n",
        "* **Sentinel-3 OLCI:** Offers data with wider swath and more frequent revisit times, beneficial for large-area monitoring.\n",
        "\n",
        "### Accessing Data:\n",
        "\n",
        "1.  **EuroSAT Dataset:**\n",
        "    * The EuroSAT dataset is publicly available and comes in two versions: RGB images and multispectral images. For this project, we'll use the RGB version as it's compatible with many pre-trained deep learning models.\n",
        "\n",
        "2.  **Copernicus Dataspace:**\n",
        "    * The Copernicus Data Space Ecosystem provides access to a vast archive of Sentinel data.\n",
        "    * Registration is required to download data. Visit the [Copernicus Dataspace registration page](https://dataspace.copernicus.eu) to create an account."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f80919",
      "metadata": {
        "id": "94f80919"
      },
      "source": [
        "## 3. Methodology\n",
        "\n",
        "We can choose between supervised or unsupervised learning approaches:\n",
        "\n",
        "1.  **Supervised Learning:**\n",
        "    * This approach requires labeled data, where each image patch is associated with a known land cover class.\n",
        "    * **Manual Labeling:** We could manually label images using tools like QGIS or IRIS if working with raw satellite data for a custom area. This is time-consuming but allows for tailored dataset creation.\n",
        "    * **Using Pre-labeled Datasets:** The EuroSAT dataset provides 27,000 labeled images, saving significant effort.\n",
        "    * **Algorithm:** We will implement a Deep Learning model, specifically a Convolutional Neural Network (CNN), using transfer learning.\n",
        "2.  **Unsupervised Classification Methods:**\n",
        "    * These methods do not require labeled data. They group pixels or image patches into clusters based on their inherent properties (e.g., spectral similarity).\n",
        "    * **Algorithms:** K-Means clustering, or more advanced deep learning-based clustering techniques.\n",
        "    * **Challenges:** Interpreting the generated clusters can be subjective and may require expert knowledge or comparison with ground truth data if available.\n",
        "    * This approach is an alternative if labeled data is scarce or unavailable.\n",
        "\n",
        "**This project will detail the supervised deep learning approach using the EuroSAT dataset and PyTorch.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f19d973",
      "metadata": {
        "id": "5f19d973"
      },
      "source": [
        "## 5. Implementation: Land Cover Classification with PyTorch\n",
        "\n",
        "The following sections implement the supervised deep learning approach using the EuroSAT dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c1da24",
      "metadata": {
        "id": "18c1da24"
      },
      "source": [
        "### 5.1 Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff55c1d",
      "metadata": {
        "id": "eff55c1d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d4db43",
      "metadata": {
        "id": "e3d4db43"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a8ecbce",
      "metadata": {
        "id": "7a8ecbce"
      },
      "source": [
        "### 5.2 Configuration\n",
        "\n",
        "Define paths, class labels, and other constants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af952bc4",
      "metadata": {
        "id": "af952bc4"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = '/content/drive/My Drive/data'\n",
        "BASE_PATH = os.path.join(ROOT_PATH, 'EuroSAT_RGB')\n",
        "DATA_CSV_PATH = os.path.join(ROOT_PATH, 'Dataset')\n",
        "FULL_DATA_CSV_FILE = os.path.join(DATA_CSV_PATH,'FULL_EUROSAT_DATA.csv')\n",
        "\n",
        "if not os.path.isdir(DATA_CSV_PATH):\n",
        "    os.makedirs(DATA_CSV_PATH)\n",
        "\n",
        "IDX_CLASS_LABELS = {\n",
        "    0: 'AnnualCrop',\n",
        "    1: 'Forest',\n",
        "    2: 'HerbaceousVegetation',\n",
        "    3: 'Highway',\n",
        "    4: 'Industrial',\n",
        "    5: 'Pasture',\n",
        "    6: 'PermanentCrop',\n",
        "    7: 'Residential',\n",
        "    8: 'River',\n",
        "    9: 'SeaLake'\n",
        "}\n",
        "CLASSES = list(IDX_CLASS_LABELS.values())\n",
        "CLASS_IDX_LABELS = {val: key for key, val in IDX_CLASS_LABELS.items()}\n",
        "\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "torch.manual_seed(10)\n",
        "VALID_SIZE = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cdc23be",
      "metadata": {
        "id": "4cdc23be"
      },
      "source": [
        "### 5.3 Utility Functions\n",
        "\n",
        "Helper functions for encoding/decoding labels and displaying image batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ed7882b",
      "metadata": {
        "id": "3ed7882b"
      },
      "outputs": [],
      "source": [
        "def encode_label(label):\n",
        "    return CLASS_IDX_LABELS[label]\n",
        "\n",
        "def decode_target(target, text_labels=True):\n",
        "    if text_labels:\n",
        "        return IDX_CLASS_LABELS[target]\n",
        "    else:\n",
        "        return target\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(16, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images.cpu(), nrow=16).permute(1, 2, 0)) #\n",
        "        break\n",
        "\n",
        "print(encode_label('Forest'))\n",
        "print(decode_target(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2a433b",
      "metadata": {
        "id": "6e2a433b"
      },
      "source": [
        "### 5.4 Data Preprocessing\n",
        "\n",
        "This step walks through the EuroSAT dataset directory (specified in `BASE_PATH`), collects all image filenames and their corresponding labels, and saves this information into a CSV file (`FULL_DATA_CSV_FILE`). This CSV is then used to load data for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03d74d5e",
      "metadata": {
        "id": "03d74d5e"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for class_name in tqdm(os.listdir(BASE_PATH)):\n",
        "    class_dir = os.path.join(BASE_PATH, class_name)\n",
        "    if os.path.isdir(class_dir) and class_name in CLASSES:\n",
        "        for image_file in os.listdir(class_dir):\n",
        "            if image_file.lower().endswith(('.jpg','.jpeg','.png','.tif','.tiff')):\n",
        "                data.append({'image_id': image_file, 'label': class_name})\n",
        "\n",
        "DATA_DF = pd.DataFrame(data)\n",
        "DATA_DF.to_csv(FULL_DATA_CSV_FILE, index=False)\n",
        "print(f\"Successfully created and saved {FULL_DATA_CSV_FILE} with {len(DATA_DF)} entries.\")\n",
        "print(DATA_DF.head())\n",
        "\n",
        "DATA_DF = pd.read_csv(FULL_DATA_CSV_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27b8534",
      "metadata": {
        "id": "b27b8534"
      },
      "source": [
        "### 5.5 Splitting Data into Training and Validation Sets\n",
        "\n",
        "Shuffle the dataset and split it into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4120afd",
      "metadata": {
        "id": "a4120afd"
      },
      "outputs": [],
      "source": [
        "\n",
        "DATA_DF = DATA_DF.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "split_index = int(len(DATA_DF)*(1-VALID_SIZE))\n",
        "TRAIN_DF = DATA_DF[:split_index]\n",
        "VALID_DF = DATA_DF[split_index:]\n",
        "TRAIN_DF.reset_index(drop=True, inplace=True)\n",
        "VALID_DF.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(f\"Training set size:{len(TRAIN_DF)}\")\n",
        "print(f\"Validation set size:{len(VALID_DF)}\")\n",
        "print(\"Training DF head:\")\n",
        "print(TRAIN_DF.head())\n",
        "print(\"Validation DF head:\")\n",
        "print(VALID_DF.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96c8799c",
      "metadata": {
        "id": "96c8799c"
      },
      "source": [
        "### 5.6 Creating PyTorch Dataset and DataLoaders\n",
        "\n",
        "Define a custom `Dataset` class for EuroSAT and create `DataLoaders` for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742b7ce2",
      "metadata": {
        "id": "742b7ce2"
      },
      "outputs": [],
      "source": [
        "class EuroSATDataset(Dataset):\n",
        "    def __init__(self, df, base_image_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.base_image_dir = base_image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) #\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.loc[idx]\n",
        "        img_id, label_str = row['image_id'], row['label']\n",
        "        img_path = os.path.join(self.base_image_dir, label_str, img_id)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Image not found at {img_path}\")\n",
        "            return None, None\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img,encode_label(label_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a0e7ce2",
      "metadata": {
        "id": "9a0e7ce2"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "train_ds = EuroSATDataset(TRAIN_DF, BASE_PATH, data_transform)\n",
        "valid_ds = EuroSATDataset(VALID_DF, BASE_PATH, data_transform)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Show a batch of training images\n",
        "show_batch(train_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b6ffa38",
      "metadata": {
        "id": "7b6ffa38"
      },
      "source": [
        "### 5.7 Model Definition\n",
        "\n",
        "Define the model architecture. We use a pre-trained `wide_resnet50_2` and add a custom classification head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b7c941",
      "metadata": {
        "id": "a7b7c941"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n",
        "\n",
        "class MulticlassClassifierBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        img, label = batch\n",
        "        out = self(img)\n",
        "        loss = criterion(out, label)\n",
        "        accu = accuracy(out, label)\n",
        "        return accu, loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        img, label = batch\n",
        "        out = self(img)\n",
        "        loss = criterion(out, label)\n",
        "        accu = accuracy(out, label)\n",
        "        return {\"val_loss\": loss.detach(), \"val_acc\": accu}\n",
        "\n",
        "    def validation_epoch_ends(self, outputs):\n",
        "        batch_loss = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_loss).mean()\n",
        "        batch_acc = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_acc).mean()\n",
        "        return {\"val_loss\": epoch_loss.item(), \"val_acc\": epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_accu: {:.4f}, lr: {:.6f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_accu'], result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc'])) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c15fca2",
      "metadata": {
        "id": "3c15fca2"
      },
      "outputs": [],
      "source": [
        "class LULC_Model(MulticlassClassifierBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use pretrained WideResNet50_2\n",
        "        self.network = models.wide_resnet50_2(weights=models.Wide_ResNet50_2_Weights.DEFAULT)\n",
        "        n_inputs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Sequential(\n",
        "            nn.Linear(n_inputs, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, NUM_CLASSES),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "\n",
        "    def freeze(self):\n",
        "        for param in self.network.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.network.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def unfreeze(self):\n",
        "        for param in self.network.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "model_test_instance = LULC_Model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86942de0",
      "metadata": {
        "id": "86942de0"
      },
      "source": [
        "### 5.8 Training:\n",
        "\n",
        "Functions to manage device (GPU) and move data/model to the selected device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58dfde8",
      "metadata": {
        "id": "b58dfde8"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            if b[0] is not None and b[1] is not None:\n",
        "                 yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_device()\n",
        "train_dl_device = DeviceDataLoader(train_dl, device)\n",
        "valid_dl_device = DeviceDataLoader(valid_dl, device)\n",
        "\n",
        "model = LULC_Model()\n",
        "model = to_device(model,device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e2b5fc",
      "metadata": {
        "id": "07e2b5fc"
      },
      "source": [
        "### 5.9 Training Loop\n",
        "\n",
        "The `fit` function handles the model training process over multiple epochs, including optimization, learning rate scheduling, evaluation, and early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f286f109",
      "metadata": {
        "id": "f286f109"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, valid_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in valid_loader]\n",
        "    return model.validation_epoch_ends(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit(epochs, max_lr, model, train_loader, valid_loader,\n",
        "        weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD,\n",
        "        max_epochs_stop=3, model_save_name='lulc_best_model.pth',\n",
        "        model_max_acc_save_name='lulc_max_acc_model.pth'):\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    valid_loss_min = np.inf\n",
        "    valid_acc_max = 0.0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    optimizer = opt_func(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        train_accuracies = []\n",
        "        lrs = []\n",
        "\n",
        "        print(f\"Starting Epoch {epoch+1}/{epochs}\")\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
        "            if batch[0] is None: continue\n",
        "            accu, loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            train_accuracies.append(accu)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "\n",
        "        result = evaluate(model, valid_loader)\n",
        "        scheduler.step(result['val_loss'])\n",
        "        # Store results\n",
        "        result[\"train_loss\"] = torch.stack(train_losses).mean().item()\n",
        "        result[\"train_accu\"] = torch.stack(train_accuracies).mean().item()\n",
        "        result[\"lrs\"] = lrs\n",
        "\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "\n",
        "        if result['val_acc'] > valid_acc_max:\n",
        "            print(f\"Validation accuracy improved from {valid_acc_max:.4f} to {result['val_acc']:.4f}. Saving model to {model_max_acc_save_name}\")\n",
        "            torch.save(model.state_dict(), model_max_acc_save_name)\n",
        "            valid_acc_max = result['val_acc']\n",
        "\n",
        "        if result['val_loss'] < valid_loss_min:\n",
        "            print(f\"Validation loss decreased from {valid_loss_min:.4f} to {result['val_loss']:.4f}. Saving model to {model_save_name}\")\n",
        "            torch.save(model.state_dict(), model_save_name)\n",
        "            valid_loss_min = result['val_loss']\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"Validation loss did not improve for {epochs_no_improve} epoch(s). Current best: {valid_loss_min:.4f}\")\n",
        "            if epochs_no_improve >= max_epochs_stop:\n",
        "                print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "                return history\n",
        "\n",
        "    print(f\"Training finished. Best validation loss: {valid_loss_min:.4f}, Best validation accuracy: {valid_acc_max:.4f}\")\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eb4be8a",
      "metadata": {
        "id": "0eb4be8a"
      },
      "source": [
        "### 5.10 Training the Model\n",
        "\n",
        "Set hyperparameters and start the training process. Initially, we'll freeze the base model and train only the classification head. Then, we can unfreeze and fine-tune the entire model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bacd8d6",
      "metadata": {
        "id": "1bacd8d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "epochs = 10\n",
        "max_lr = 1e-4\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "max_epochs_stop_early = 5\n",
        "\n",
        "# saving models\n",
        "model_save_dir = os.path.join(ROOT_PATH, 'Models')\n",
        "if not os.path.isdir(model_save_dir):\n",
        "    os.makedirs(model_save_dir)\n",
        "\n",
        "best_loss_model_path = os.path.join(model_save_dir, 'eurosat_best_loss.pth')\n",
        "max_acc_model_path = os.path.join(model_save_dir, 'eurosat_max_acc.pth')\n",
        "\n",
        "# evaluate model before training\n",
        "initial_eval = evaluate(model, valid_dl_device)\n",
        "print(f\"Initial Validation Loss: {initial_eval['val_loss']:.4f}, Initial Validation Acc: {initial_eval['val_acc']:.4f}\")\n",
        "\n",
        "# freeze layers\n",
        "model.freeze()\n",
        "history_frozen = fit(epochs=epochs,\n",
        "            max_lr=max_lr,\n",
        "            model=model,\n",
        "            train_loader=train_dl_device,\n",
        "            valid_loader=valid_dl_device,\n",
        "            weight_decay=weight_decay,\n",
        "            grad_clip=grad_clip,\n",
        "            opt_func=opt_func,\n",
        "            max_epochs_stop=max_epochs_stop_early,\n",
        "            model_save_name=best_loss_model_path,\n",
        "            model_max_acc_save_name=max_acc_model_path)\n",
        "history = history_frozen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ef3de7",
      "metadata": {
        "id": "10ef3de7"
      },
      "source": [
        "### 5.11 Plotting Training Results\n",
        "\n",
        "Visualize training and validation loss, accuracy, and learning rates over epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90d634f5",
      "metadata": {
        "id": "90d634f5"
      },
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "    if not history: return\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx', label='Training Loss')\n",
        "    plt.plot(val_losses, '-rx', label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss vs. Epochs')\n",
        "    plt.show()\n",
        "\n",
        "def plot_accuracies(history):\n",
        "    if not history: return\n",
        "    train_accu = [x.get('train_accu') for x in history]\n",
        "    val_accu = [x['val_acc'] for x in history]\n",
        "    plt.plot(train_accu, '-bx', label='Training Accuracy')\n",
        "    plt.plot(val_accu, '-rx', label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy vs. Epochs')\n",
        "    plt.show()\n",
        "\n",
        "def plot_lrs(history):\n",
        "    if not history: return\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.title('Learning Rate vs. Batch no.')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_losses(history)\n",
        "plot_accuracies(history)\n",
        "plot_lrs(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c681c5",
      "metadata": {
        "id": "82c681c5"
      },
      "source": [
        "### 5.12 Prediction and Evaluation on the Validation Set\n",
        "\n",
        "Load the best model and evaluate its performance on the Validation Set. This includes generating a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027c2e68",
      "metadata": {
        "id": "027c2e68"
      },
      "outputs": [],
      "source": [
        "def predict_single_image(model_loaded, image_tensor, device_to_use):\n",
        "    model_loaded.eval()\n",
        "    with torch.no_grad():\n",
        "        xb = image_tensor.unsqueeze(0)\n",
        "        xb = to_device(xb, device_to_use)\n",
        "        preds = model_loaded(xb)\n",
        "        _, prediction_idx = torch.max(preds.cpu().detach(), dim=1)\n",
        "    return decode_target(prediction_idx.item(), text_labels=True)\n",
        "\n",
        "def display_prediction(image_tensor, actual_label_idx, predicted_label_str):\n",
        "    plt.imshow(image_tensor.permute(1, 2, 0).cpu())\n",
        "    actual_label_str = decode_target(actual_label_idx)\n",
        "    plt.title(f\"Actual: {actual_label_str}\\nPredicted: {predicted_label_str}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "best_model_path_to_load = os.path.join(ROOT_PATH, 'Models', 'eurosat_max_acc.pth')\n",
        "                                                                                # Original notebook used '/content/lulc_max_acc.pth'\n",
        "\n",
        "loaded_model = LULC_Model()\n",
        "print(f\"Loading best accuracy model from: {best_model_path_to_load}\")\n",
        "loaded_model.load_state_dict(torch.load(best_model_path_to_load, map_location=device))\n",
        "loaded_model = to_device(loaded_model, device)\n",
        "loaded_model.eval()\n",
        "\n",
        "num_samples_to_show = 3\n",
        "for i in range(min(num_samples_to_show, len(valid_ds))):\n",
        "    img_tensor, actual_idx = valid_ds[i]\n",
        "    if img_tensor is not None:\n",
        "        predicted_class = predict_single_image(loaded_model, img_tensor, device)\n",
        "        print(f\"Sample {i+1}: Actual='{decode_target(actual_idx)}', Predicted='{predicted_class}'\")\n",
        "    else:\n",
        "        print(f\"Sample {i+1} could not be loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f27ac59",
      "metadata": {
        "id": "0f27ac59"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def get_all_predictions(model_to_eval, data_loader, device_to_use):\n",
        "    model_to_eval.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for batch in tqdm(data_loader, desc=\"Getting All Predictions\"):\n",
        "        if batch[0] is None: continue\n",
        "        images, labels = batch\n",
        "        outputs = model_to_eval(images)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "y_pred, y_true = get_all_predictions(loaded_model, valid_dl_device, device)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "overall_accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "print(f\"Overall Validation Accuracy from CM: {overall_accuracy:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES, cmap='Blues') #\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix - Validation Set')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c33f0cc1",
      "metadata": {
        "id": "c33f0cc1"
      },
      "source": [
        "## 8. Assessment of the Environmental Cost\n",
        "\n",
        "Deep learning projects, especially those involving large datasets and complex models, can have an environmental impact primarily due to the electricity consumed during model training and experimentation. It's important to be mindful of this.\n",
        "\n",
        "**Key Factors Contributing to Environmental Cost:**\n",
        "\n",
        "1.  **Computational Resources (Training):**\n",
        "    * Training deep learning models like `wide_resnet50_2` requires significant GPU or CPU processing time. This is the largest contributor.\n",
        "    * The energy consumption depends on the hardware used (GPUs are power-intensive), the duration of training, and the efficiency of the code.\n",
        "    * For this project, training for 10 epochs on the EuroSAT dataset (27000 images of 64x64, upscaled to 224x224) using a platform like Google Colab still consumes energy.\n",
        "\n",
        "2.  **Data Storage and Transfer:**\n",
        "    * The EuroSAT dataset (RGB version) is a few gigabytes in size. Storing this data on local drives or cloud storage consumes energy continuously, albeit less than active computation.\n",
        "    * Downloading the dataset from its source also consumes energy through network infrastructure.\n",
        "\n",
        "3.  **Hyperparameter Tuning:**\n",
        "    * Multiple training runs with different hyperparameters (learning rates, batch sizes, model variations) multiply the computational cost.\n",
        "\n",
        "\n",
        "**Mitigation Strategies :**\n",
        "\n",
        "* **Transfer Learning:** Using a pre-trained model (`wide_resnet50_2`) significantly reduces the required training time and data compared to training a large model from scratch. This is a major energy-saving practice.\n",
        "* **Efficient Data Loading:** Using `num_workers` in `DataLoader` can speed up data loading, potentially reducing overall training time if I/O is a bottleneck.\n",
        "* **Early Stopping:** The implemented early stopping mechanism prevents unnecessary training epochs if the model's performance on the validation set ceases to improve, saving computational resources.\n",
        "* **Appropriate Batch Size:** Choosing a reasonable batch size helps balance memory usage and training speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OGQKgAqocmZk",
      "metadata": {
        "id": "OGQKgAqocmZk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}